{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1RLc2Z4FmrjCKWzMHEaC-zQFKSDP6CZHM",
      "authorship_tag": "ABX9TyPweGyk5zfMAxvhzag+5I0+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "267a3acbae1b44aa9955a24602842f40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5727b4fc65b043d7b9eb35b327eca7c7",
              "IPY_MODEL_c1bd4b04a7794c1b92bbfa80d8efb49d",
              "IPY_MODEL_3babbbd5e8444ef3bd370f336b5a1f07"
            ],
            "layout": "IPY_MODEL_41d82eea4d974d23b4930e78fa686038"
          }
        },
        "5727b4fc65b043d7b9eb35b327eca7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df307d3d25bf4803a655865a687b22a8",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bd04695ae538455390ed690d97495998",
            "value": "Batches:â€‡100%"
          }
        },
        "c1bd4b04a7794c1b92bbfa80d8efb49d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4298df34aea942f8aaeacb5f51e65318",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21d5897ef88748f1b889b2065a6c99e1",
            "value": 2
          }
        },
        "3babbbd5e8444ef3bd370f336b5a1f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e9687d363e64663af6895d9eb352e97",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_382af840e9d54060b3bef1e501d5c787",
            "value": "â€‡2/2â€‡[00:09&lt;00:00,â€‡â€‡3.92s/it]"
          }
        },
        "41d82eea4d974d23b4930e78fa686038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df307d3d25bf4803a655865a687b22a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd04695ae538455390ed690d97495998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4298df34aea942f8aaeacb5f51e65318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21d5897ef88748f1b889b2065a6c99e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e9687d363e64663af6895d9eb352e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382af840e9d54060b3bef1e501d5c787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dthaker05/QueryQuill_ml_backend/blob/main/QueryQuill_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhD7XhHL6hnW",
        "outputId": "3ed4f4fb-72c3-4cf9-cfb8-e6d2ae7e27d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.123.10)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.50.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.51.0,>=0.40.0->fastapi) (4.12.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.9)\n",
            "Requirement already satisfied: pdfminer.six==20251230 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20251230)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (5.3.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.9)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: pdfminer.six==20251230 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20251230)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (5.3.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251230->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251230->pdfplumber) (2.23)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn spacy nltk scikit-learn sentence-transformers pandas numpy\n",
        "!pip install pdfplumber\n",
        "!pip install faiss-cpu sentence-transformers pdfplumber\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnnSaFwJ7Q_d",
        "outputId": "c6721ac8-6985-4812-fad8-a3f67c3fd433"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import random\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n"
      ],
      "metadata": {
        "id": "vv2kKyyv8KgN"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    pages_text = []\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                pages_text.append(text)\n",
        "\n",
        "    return \"\\n\".join(pages_text)\n"
      ],
      "metadata": {
        "id": "NWE7ttI1JA6q"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n"
      ],
      "metadata": {
        "id": "BdRVmPKfJG_L"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "def build_faiss_index(text, model):\n",
        "    sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 30]\n",
        "\n",
        "    embeddings = model.encode(sentences, show_progress_bar=True)\n",
        "    embeddings = np.array(embeddings).astype(\"float32\")\n",
        "\n",
        "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "    index.add(embeddings)\n",
        "\n",
        "    return index, sentences\n"
      ],
      "metadata": {
        "id": "i-yb85UjJXKe"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ingest_new_book(pdf_path, book_metadata):\n",
        "    print(\"ðŸ“˜ Ingesting new book:\", book_metadata[\"title\"])\n",
        "\n",
        "    # Step 1: Extract text\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    print(\"âœ… Text extracted\")\n",
        "\n",
        "    # Step 2: Build semantic index\n",
        "    index, sentences = build_faiss_index(text, embedding_model)\n",
        "    print(\"âœ… Semantic index created\")\n",
        "\n",
        "    book_object = {\n",
        "        \"metadata\": book_metadata,\n",
        "        \"full_text\": text,\n",
        "        \"faiss_index\": index,\n",
        "        \"sentences\": sentences\n",
        "    }\n",
        "\n",
        "    print(\"ðŸš€ Book ingestion completed\")\n",
        "    return book_object\n"
      ],
      "metadata": {
        "id": "Hf3qxJbnJfa5"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "metadata = {\n",
        "    \"book_id\": \"OS_001\",\n",
        "    \"title\": \"Operating Systems\",\n",
        "    \"subject\": \"Computer Science\"\n",
        "}\n",
        "\n",
        "book = ingest_new_book(pdf_path, metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "267a3acbae1b44aa9955a24602842f40",
            "5727b4fc65b043d7b9eb35b327eca7c7",
            "c1bd4b04a7794c1b92bbfa80d8efb49d",
            "3babbbd5e8444ef3bd370f336b5a1f07",
            "41d82eea4d974d23b4930e78fa686038",
            "df307d3d25bf4803a655865a687b22a8",
            "bd04695ae538455390ed690d97495998",
            "4298df34aea942f8aaeacb5f51e65318",
            "21d5897ef88748f1b889b2065a6c99e1",
            "7e9687d363e64663af6895d9eb352e97",
            "382af840e9d54060b3bef1e501d5c787"
          ]
        },
        "id": "tEYMDnruJkIK",
        "outputId": "f62a7b69-786f-4618-8087-3319fd54ffd6"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“˜ Ingesting new book: Operating Systems\n",
            "âœ… Text extracted\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "267a3acbae1b44aa9955a24602842f40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Semantic index created\n",
            "ðŸš€ Book ingestion completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_retrieval_size(num_questions):\n",
        "    \"\"\"\n",
        "    Decide how much content to fetch so students are well prepared\n",
        "    \"\"\"\n",
        "    BASE_CONTEXT = 40        # minimum sentences for good coverage\n",
        "    CONTEXT_MULTIPLIER = 2  # scale with number of questions\n",
        "    MAX_CONTEXT = 120       # upper safety limit\n",
        "\n",
        "    return min(\n",
        "        max(BASE_CONTEXT, num_questions * CONTEXT_MULTIPLIER),\n",
        "        MAX_CONTEXT\n",
        "    )\n"
      ],
      "metadata": {
        "id": "DFVFKetOcg0L"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_from_book(\n",
        "    book,\n",
        "    topic,\n",
        "    difficulty,\n",
        "    user_requested_questions\n",
        "):\n",
        "\n",
        "\n",
        "    # Step 1: Decide how much knowledge to fetch\n",
        "    retrieval_k = calculate_retrieval_size(num_questions)\n",
        "    relevant_sentences = retrieve_relevant_content(book, topic, top_k=retrieval_k)\n",
        "    context = prepare_context(relevant_sentences)\n",
        "\n",
        "    # Step 4: Generate exactly what user asked for\n",
        "    questions = questions.append({\n",
        "    \"type\": \"descriptive\",   # ðŸ”¹ ADD THIS LINE\n",
        "    \"question\": question_text,\n",
        "    \"answer\": f\"{keyword} explanation based on the given context.\"\n",
        "})\n",
        "\n",
        "\n",
        "    return questions\n",
        ""
      ],
      "metadata": {
        "id": "XVPdN69gc4Go"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_context(relevant_sentences):\n",
        "    \"\"\"\n",
        "    Combines retrieved sentences into a single context string\n",
        "    \"\"\"\n",
        "    return \". \".join(relevant_sentences)\n"
      ],
      "metadata": {
        "id": "rLCn0P-ofZwB"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_distractors(correct_answer, keywords, num_distractors=3):\n",
        "    distractors = set()\n",
        "\n",
        "    while len(distractors) < num_distractors:\n",
        "        candidate = random.choice(keywords)\n",
        "        if candidate.lower() != correct_answer.lower():\n",
        "            distractors.add(candidate.title())\n",
        "\n",
        "    return list(distractors)\n",
        "\n"
      ],
      "metadata": {
        "id": "qBMhJM7Qdwp2"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mcq(keyword, context_keywords):\n",
        "    question = f\"Which of the following best describes {keyword}?\"\n",
        "\n",
        "    correct_answer = keyword.title()\n",
        "    distractors = generate_distractors(correct_answer, context_keywords)\n",
        "\n",
        "    options = distractors + [correct_answer]\n",
        "    random.shuffle(options)\n",
        "\n",
        "    return {\n",
        "        \"type\": \"mcq\",\n",
        "        \"question\": question,\n",
        "        \"options\": options,\n",
        "        \"correct_answer\": correct_answer\n",
        "    }"
      ],
      "metadata": {
        "id": "iD-fDr57dz7D"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords(text, num_keywords=10):\n",
        "    # Assuming nlp (spacy model) is loaded globally\n",
        "    doc = nlp(text)\n",
        "    # Filter for meaningful tokens: alphabetic, not stop words, common parts of speech\n",
        "    keywords = [token.text for token in doc if token.is_alpha and not token.is_stop and token.pos_ in ['NOUN', 'PROPN', 'ADJ', 'VERB']]\n",
        "    # Simple deduplication and selection of top keywords\n",
        "    unique_keywords = list(dict.fromkeys(keywords))\n",
        "    return unique_keywords[:num_keywords]\n",
        "\n",
        "def generate_mcqs(context, num_mcqs=5):\n",
        "    keywords = extract_keywords(context)\n",
        "\n",
        "    mcqs = []\n",
        "    used = set()\n",
        "\n",
        "    for keyword in keywords:\n",
        "        # â˜€\u0005 FILTER WEAK KEYWORDS (THIS IS THE LINE YOU ASKED ABOUT)\n",
        "        if len(keyword.split()) < 2:\n",
        "            continue\n",
        "\n",
        "        if len(mcqs) >= num_mcqs:\n",
        "            break\n",
        "\n",
        "        if keyword not in used:\n",
        "            mcqs.append(generate_mcq(keyword, keywords))\n",
        "            used.add(keyword)\n",
        "\n",
        "    return mcqs"
      ],
      "metadata": {
        "id": "esIS77uLd24M"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_mcq(student_answer, correct_answer):\n",
        "    return 1 if student_answer == correct_answer else 0\n"
      ],
      "metadata": {
        "id": "8v-iWb4Xd-z1"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Assuming embedding_model is loaded globally\n",
        "\n",
        "def evaluate_answer(student_answer, correct_answer):\n",
        "    student_embedding = embedding_model.encode([student_answer])\n",
        "    correct_embedding = embedding_model.encode([correct_answer])\n",
        "\n",
        "    similarity = cosine_similarity(student_embedding, correct_embedding)[0][0]\n",
        "    score = max(0, min(10, int(similarity * 10))) # Scale 0-1 similarity to 0-10 score\n",
        "    if similarity > 0.8: # Consider high similarity as perfect score for simplicity\n",
        "        score = 10\n",
        "    return score, similarity\n",
        "\n",
        "def evaluate_descriptive(student_answer, correct_answer):\n",
        "    score, similarity = evaluate_answer(student_answer, correct_answer)\n",
        "\n",
        "    return {\n",
        "        \"score\": score,\n",
        "        \"similarity\": round(similarity, 2)\n",
        "    }"
      ],
      "metadata": {
        "id": "Jwxlqr5ceB6R"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_response(question, student_answer):\n",
        "    if question[\"type\"] == \"mcq\":\n",
        "        score = evaluate_mcq(student_answer, question[\"correct_answer\"])\n",
        "        return {\n",
        "            \"score\": score,\n",
        "            \"max_score\": 1\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        result = evaluate_descriptive(student_answer, question[\"answer\"])\n",
        "        return {\n",
        "            \"score\": result[\"score\"],\n",
        "            \"similarity\": result[\"similarity\"],\n",
        "            \"max_score\": 10\n",
        "        }\n"
      ],
      "metadata": {
        "id": "y9C6g-oLeCr0"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def difficulty_split(total_questions):\n",
        "    return {\n",
        "        \"easy\": int(total_questions * 0.4),\n",
        "        \"medium\": int(total_questions * 0.4),\n",
        "        \"hard\": total_questions - int(total_questions * 0.8)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "X-waDQozeN8i"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming QUESTION_TEMPLATES is a global dictionary\n",
        "# Assuming extract_keywords is defined\n",
        "import random # Ensure random is available for shuffling keywords\n",
        "\n",
        "def generate_questions(text, difficulty, num_questions):\n",
        "    questions = []\n",
        "    keywords = extract_keywords(text) # Assumes extract_keywords is defined\n",
        "    random.shuffle(keywords)\n",
        "\n",
        "    if not keywords:\n",
        "        return []\n",
        "\n",
        "    templates = QUESTION_TEMPLATES.get(difficulty, [])\n",
        "    if not templates:\n",
        "        return []\n",
        "\n",
        "    for i in range(num_questions):\n",
        "        if not keywords:\n",
        "            break\n",
        "        keyword = keywords.pop()\n",
        "\n",
        "        template = random.choice(templates)\n",
        "        question_text = template.format(keyword=keyword.title())\n",
        "\n",
        "        questions.append({\n",
        "            \"type\": \"descriptive\", # Ensure 'type' key is present\n",
        "            \"question\": question_text,\n",
        "            \"answer\": f\"{keyword} explanation based on the given context.\"\n",
        "        })\n",
        "    return questions\n",
        "\n",
        "def generate_balanced_test(\n",
        "    book,\n",
        "    topic,\n",
        "    total_questions\n",
        "):\n",
        "    split = difficulty_split(total_questions)\n",
        "\n",
        "    retrieval_k = calculate_retrieval_size(total_questions)\n",
        "    context = prepare_context(\n",
        "        retrieve_relevant_content(book, topic, retrieval_k)\n",
        "    )\n",
        "\n",
        "    test = []\n",
        "\n",
        "    # EASY (MCQs)\n",
        "    test.extend(generate_mcqs(context, split[\"easy\"]))\n",
        "\n",
        "    # MEDIUM (Mixed)\n",
        "    test.extend(\n",
        "        generate_questions(\n",
        "            context,\n",
        "            difficulty=\"medium\",\n",
        "            num_questions=split[\"medium\"]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # HARD (Descriptive)\n",
        "    test.extend(\n",
        "        generate_questions(\n",
        "            context,\n",
        "            difficulty=\"hard\",\n",
        "            num_questions=split[\"hard\"]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return test"
      ],
      "metadata": {
        "id": "xhXM6XnxeR-2"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"operating systems concepts\"\n",
        "num_questions = 5\n",
        "\n",
        "retrieval_k = calculate_retrieval_size(num_questions)\n",
        "relevant_sentences = retrieve_relevant_content(book, topic, top_k=retrieval_k)\n",
        "context = prepare_context(relevant_sentences)\n",
        "\n",
        "mcqs = generate_mcqs(context, num_mcqs=num_questions)\n",
        "\n",
        "for q in mcqs:\n",
        "    print(q)\n",
        "\n",
        "test = generate_balanced_test(\n",
        "    book=book,\n",
        "    topic=\"deadlock prevention\",\n",
        "    total_questions=15\n",
        ")\n",
        "\n",
        "print(\"Full test list:\")\n",
        "for q in test:\n",
        "    print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A5V1Bn3eUcP",
        "outputId": "ae238c13-d8a4-4d14-c683-2f48d295b11f"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full test list:\n",
            "{'type': 'descriptive', 'question': 'Explain M.', 'answer': 'm explanation based on the given context.'}\n",
            "{'type': 'descriptive', 'question': 'How does Network work?', 'answer': 'network explanation based on the given context.'}\n",
            "{'type': 'descriptive', 'question': 'Explain Entire.', 'answer': 'Entire explanation based on the given context.'}\n",
            "{'type': 'descriptive', 'question': 'Explain High.', 'answer': 'High explanation based on the given context.'}\n",
            "{'type': 'descriptive', 'question': 'Explain Error.', 'answer': 'error explanation based on the given context.'}\n",
            "{'type': 'descriptive', 'question': 'How does Thin work?', 'answer': 'thin explanation based on the given context.'}\n",
            "{'type': 'descriptive', 'question': 'Why is Entire important?', 'answer': 'Entire explanation based on the given context.'}\n",
            "{'type': 'descriptive', 'question': 'Explain Rate with an example.', 'answer': 'rate explanation based on the given context.'}\n",
            "{'type': 'descriptive', 'question': 'Explain Distance with an example.', 'answer': 'distance explanation based on the given context.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_answers = [\n",
        "    {\"question_id\": 0, \"answer\": \"Deadlock prevention\"},\n",
        "    {\"question_id\": 1, \"answer\": \"Circular wait is avoided\"},\n",
        "    ...\n",
        "]\n"
      ],
      "metadata": {
        "id": "P3LRHcvTpMn4"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test(test_questions, student_answers):\n",
        "    results = []\n",
        "    total_score = 0\n",
        "    max_score = 0\n",
        "\n",
        "    for idx, question in enumerate(test_questions):\n",
        "        student_answer = student_answers[idx][\"answer\"]\n",
        "\n",
        "        if question[\"type\"] == \"mcq\":\n",
        "            score = 1 if student_answer == question[\"correct_answer\"] else 0\n",
        "            feedback = (\n",
        "                \"Correct answer.\"\n",
        "                if score == 1\n",
        "                else f\"Incorrect. Correct answer is {question['correct_answer']}.\"\n",
        "            )\n",
        "            max_q_score = 1\n",
        "\n",
        "        else:\n",
        "            score, similarity = evaluate_answer(\n",
        "                student_answer,\n",
        "                question[\"answer\"]\n",
        "            )\n",
        "\n",
        "            feedback = (\n",
        "                \"Excellent explanation.\"\n",
        "                if score >= 8\n",
        "                else \"Good attempt, but missing some points.\"\n",
        "                if score >= 5\n",
        "                else \"Answer is incomplete or incorrect.\"\n",
        "            )\n",
        "            max_q_score = 10\n",
        "\n",
        "        total_score += score\n",
        "        max_score += max_q_score\n",
        "\n",
        "        results.append({\n",
        "            \"question\": question[\"question\"],\n",
        "            \"student_answer\": student_answer,\n",
        "            \"score\": score,\n",
        "            \"max_score\": max_q_score,\n",
        "            \"feedback\": feedback\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"total_score\": total_score,\n",
        "        \"max_score\": max_score,\n",
        "        \"percentage\": round((total_score / max_score) * 100, 2),\n",
        "        \"detailed_results\": results\n",
        "    }\n"
      ],
      "metadata": {
        "id": "p1pKGKKnpNfd"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def overall_feedback(percentage):\n",
        "    if percentage >= 85:\n",
        "        return \"Excellent performance. Strong conceptual understanding.\"\n",
        "    elif percentage >= 60:\n",
        "        return \"Good performance. Some areas need improvement.\"\n",
        "    else:\n",
        "        return \"Needs improvement. Revise the topic thoroughly.\"\n"
      ],
      "metadata": {
        "id": "9YAjeIaApPYy"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def submit_test(test_questions, student_answers):\n",
        "    evaluation = evaluate_test(test_questions, student_answers)\n",
        "    summary = overall_feedback(evaluation[\"percentage\"])\n",
        "\n",
        "    evaluation[\"summary\"] = summary\n",
        "    return evaluation\n"
      ],
      "metadata": {
        "id": "z0esmeUGpSkP"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake student answers for testing\n",
        "student_answers = [\n",
        "    {\"answer\": q[\"correct_answer\"] if q[\"type\"] == \"mcq\" else \"Deadlock can be prevented by avoiding circular wait\"}\n",
        "    for q in test\n",
        "]\n",
        "\n",
        "result = submit_test(test, student_answers)\n",
        "\n",
        "print(result[\"percentage\"])\n",
        "print(result[\"summary\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udjk8hW8pVOf",
        "outputId": "8cb22036-e64c-44a5-ce41-15a06467a1b7"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.33\n",
            "Needs improvement. Revise the topic thoroughly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "app = FastAPI(title=\"QueryQuill Assessment API\")\n",
        "\n",
        "# -------------------------\n",
        "# GLOBAL STATE (TEMPORARY)\n",
        "# -------------------------\n",
        "current_test = None\n",
        "\n",
        "\n",
        "# -------- REQUEST MODELS --------\n",
        "class GenerateTestRequest(BaseModel):\n",
        "    topic: str\n",
        "    total_questions: int\n",
        "\n",
        "\n",
        "class SubmitTestRequest(BaseModel):\n",
        "    answers: List[str]\n",
        "\n",
        "\n",
        "# -------- API ENDPOINTS --------\n",
        "@app.post(\"/generate-test\")\n",
        "def generate_test_api(data: GenerateTestRequest):\n",
        "    global current_test\n",
        "\n",
        "    current_test = generate_balanced_test(\n",
        "        book=book,  # already ingested book\n",
        "        topic=data.topic,\n",
        "        total_questions=data.total_questions\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"total_questions\": len(current_test),\n",
        "        \"questions\": current_test\n",
        "    }\n",
        "\n",
        "\n",
        "@app.post(\"/submit-test\")\n",
        "def submit_test_api(data: SubmitTestRequest):\n",
        "    global current_test\n",
        "\n",
        "    if current_test is None:\n",
        "        return {\"error\": \"No active test found. Generate a test first.\"}\n",
        "\n",
        "    student_answers = [{\"answer\": ans} for ans in data.answers]\n",
        "\n",
        "    result = submit_test(current_test, student_answers)\n",
        "    return result\n",
        "\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health_check():\n",
        "    return {\"status\": \"QueryQuill ML API running\"}\n"
      ],
      "metadata": {
        "id": "iqxdPD-3uPnc"
      },
      "execution_count": 161,
      "outputs": []
    }
  ]
}